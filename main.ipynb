{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup do Ambiente"
      ],
      "metadata": {
        "id": "fdfFPEJL3CLJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rszAxEbZOA43"
      },
      "outputs": [],
      "source": [
        "!pip install -q unsloth[colab-new] faiss-cpu sentence-transformers datasets accelerate trl peft transformers\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install transformers datasets\n",
        "\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from transformers import pipeline\n",
        "from transformers import TrainingArguments\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WyGzkc5ez3a"
      },
      "source": [
        "# Download e exploração inicial dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CuxJtGggAxGf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/pubmedqa/pubmedqa.git\n",
        "\n",
        "file_path = 'pubmedqa/data/ori_pqal.json'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "sample_key = list(data.keys())[0]\n",
        "print(f\"\\nCampos disponíveis: {list(data[sample_key].keys())}\\n\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Exploração de dados - PubMedQA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, key in enumerate(list(data.keys())[:3]):\n",
        "    item = data[key]\n",
        "\n",
        "    print(f\"\\nExemplo {i+1} | ID: {key}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Question: {item.get('QUESTION', 'N/A')}\")\n",
        "\n",
        "    context = \" \".join(item.get('CONTEXTS', []))\n",
        "    print(f\"Context: {context[:300]}...\")\n",
        "\n",
        "    print(f\"Labels: {item.get('LABELS', 'N/A')}\")\n",
        "    print(f\"Decision: {item.get('final_decision', 'N/A')}\")\n",
        "    print(f\"Answer: {item.get('LONG_ANSWER', 'N/A')[:200]}...\")\n",
        "    print(f\"Meshes: {item.get('MESHES', 'N/A')}\")\n",
        "    print(f\"Year: {item.get('YEAR', 'N/A')}\")\n",
        "    print(f\"Reasoning required pred: {item.get('reasoning_required_pred', 'N/A')}\")\n",
        "    print(f\"Reasoning free pred: {item.get('reasoning_free_pred', 'N/A')}\")\n",
        "\n",
        "print(f\"\\n\\nTotal de registros: {len(data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFH2sIYarWe"
      },
      "source": [
        "# Pré-processamento + Anonimização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4fd06e94"
      },
      "outputs": [],
      "source": [
        "MAP_DECISION = {\n",
        "  \"yes\": \"SIM\",\n",
        "  \"no\": \"NÃO\",\n",
        "  \"maybe\": \"TALVEZ\"\n",
        "}\n",
        "\n",
        "\n",
        "def anonymize_text(text):\n",
        "    \"\"\"Remove dados sensíveis (LGPD/HIPAA compliance)\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'(Dr\\.|Dra\\.|Doctor|Prof\\.|MD)\\s+[A-Z][a-z]+(\\s+[A-Z][a-z]+)?', '[NOME]', text)\n",
        "    text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', '[EMAIL]', text)\n",
        "    locations = r'(Israel|Denmark|Chile|Texas|France|United Kingdom|UK|USA|Pakistan|Karachi|Jordan|Japan|Australia|North Carolina|Washington)'\n",
        "    text = re.sub(locations, '[LOCAL]', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\b\\d{6,}\\b', '[ID]', text)\n",
        "    text = re.sub(r'\\b(19|20)\\d{2}\\b', '[ANO]', text)\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[URL]', text)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "  if not text:\n",
        "    return \"\"\n",
        "  text = unicodedata.normalize(\"NFKC\", text)\n",
        "  text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "  text = anonymize_text(text)\n",
        "\n",
        "  return text\n",
        "\n",
        "\n",
        "processed_docs = []\n",
        "\n",
        "for item in data.values():\n",
        "  question = clean_text(item.get(\"QUESTION\"))\n",
        "  context = clean_text(\" \".join(item.get(\"CONTEXTS\", [])))\n",
        "  answer = clean_text(item.get(\"LONG_ANSWER\", \"\"))\n",
        "  decision = MAP_DECISION.get(item.get(\"final_decision\", \"\"), \"\")\n",
        "\n",
        "\n",
        "  if question and context:\n",
        "    processed_docs.append({\n",
        "      \"question\": question,\n",
        "      \"context\": context,\n",
        "      \"answer\": answer,\n",
        "      \"decision\": decision,\n",
        "      \"year\": item.get(\"YEAR\")\n",
        "    })\n",
        "\n",
        "\n",
        "print(len(processed_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Database em português para treinamento do modelo"
      ],
      "metadata": {
        "id": "eOou-BxIaFMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/rag/language_alignment_pt.json\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "print(dataset.column_names)\n",
        "\n",
        "def messages_to_text(example):\n",
        "    text = \"\"\n",
        "    for msg in example[\"messages\"]:\n",
        "        if msg[\"role\"] == \"system\":\n",
        "            text += f\"<<SYS>>\\n{msg['content']}\\n<</SYS>>\\n\\n\"\n",
        "        elif msg[\"role\"] == \"user\":\n",
        "            text += f\"[INST] {msg['content']} [/INST]\\n\"\n",
        "        elif msg[\"role\"] == \"assistant\":\n",
        "            text += msg[\"content\"]\n",
        "    return {\"text\": text}\n",
        "\n",
        "dataset = dataset.map(\n",
        "    messages_to_text,\n",
        "    batched=False,\n",
        "    remove_columns=[\"messages\"]\n",
        ")\n",
        "\n",
        "print(dataset.column_names)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "id": "Q3r9Q4rFGh0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação para RAG Médico"
      ],
      "metadata": {
        "id": "CN9H1ot25hIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_documents = []\n",
        "\n",
        "for d in processed_docs:\n",
        "  text = f\"\"\"\n",
        "  Pergunta científica:\n",
        "  {d['question']}\n",
        "\n",
        "\n",
        "  Evidência:\n",
        "  {d['context']}\n",
        "\n",
        "\n",
        "  Conclusão:\n",
        "  {d['answer']}\n",
        "  \"\"\"\n",
        "  rag_documents.append(text.strip())\n",
        "\n",
        "\n",
        "len(rag_documents)"
      ],
      "metadata": {
        "id": "jdL40-3R5nXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Criação de Embeddings + Índice FAISS"
      ],
      "metadata": {
        "id": "236_nIoK52PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "embeddings = embedder.encode(rag_documents, show_progress_bar=True)\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(np.array(embeddings))\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('/content/drive/MyDrive/rag', exist_ok=True)\n",
        "\n",
        "faiss.write_index(index, \"/content/drive/MyDrive/rag/medical_index.faiss\")\n",
        "\n",
        "with open('/content/drive/MyDrive/rag/medical_docs.json', 'w') as f:\n",
        "  json.dump(rag_documents, f)"
      ],
      "metadata": {
        "id": "hm0TXEBX56wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tunning LoRA"
      ],
      "metadata": {
        "id": "l9uXJezHAtls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0.05,\n",
        ")"
      ],
      "metadata": {
        "id": "vaTkGNFE8NhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento do modelo para respostas em Português"
      ],
      "metadata": {
        "id": "-rgHPIbcaTwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    args=training_args,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    packing=False\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "sefogQu3LnHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvando o modelo no HuggingFace"
      ],
      "metadata": {
        "id": "mWe9atPtaZ8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar env\n",
        "ENV_PATH = \"/content/drive/MyDrive/token-hf/env\"\n",
        "load_dotenv(ENV_PATH)\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "HF_REPO = f\"{os.getenv(\"HF_USER_REPO\")}/assistente-medico-lora\"\n",
        "model.push_to_hub(HF_REPO)\n",
        "tokenizer.push_to_hub(HF_REPO)"
      ],
      "metadata": {
        "id": "8WSXHwDBXptL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação da llm com Prompt"
      ],
      "metadata": {
        "id": "vDpkA6Dla3rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "Você é um assistente médico virtual.\n",
        "Responda sempre em português, com linguagem clara, empática e baseada em evidências científicas.\n",
        "\n",
        "\n",
        "Regras:\n",
        "- Não invente informações.\n",
        "- Se não houver evidência suficiente, diga isso explicitamente.\n",
        "- Não prescreva medicamentos nem indique tratamentos específicos.\n",
        "- Não indique remédios ou tratamentos.\n",
        "- Quando perguntarem por algum remédio, você deve responder: Não estou autorizado a prescrever medicamentos, por favor, consulte um médico.\n",
        "- Sempre cite a fonte da informação científica\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/drive/MyDrive/rag/medical_docs.json') as f:\n",
        "  docs = json.load(f)\n",
        "\n",
        "index = faiss.read_index('/content/drive/MyDrive/rag/medical_index.faiss')\n",
        "\n",
        "llm = pipeline(\n",
        "  \"text-generation\",\n",
        "  model=model,\n",
        "  tokenizer=tokenizer,\n",
        "  max_new_tokens=300,\n",
        "  temperature=0.0,\n",
        "  do_sample=False,\n",
        "  repetition_penalty=1.1,\n",
        "  return_full_text=False,\n",
        "  eos_token_id=tokenizer.eos_token_id\n",
        "  )\n",
        "\n",
        "def retrieve_context(question, k=3):\n",
        "  q_emb = embedder.encode([question])\n",
        "  _, idx = index.search(q_emb, k)\n",
        "  return \"\\n\\n\".join([docs[i] for i in idx[0]])\n",
        "\n",
        "def medical_chat(question):\n",
        "  context = retrieve_context(question)\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "{SYSTEM_PROMPT}\n",
        "\n",
        "\n",
        "Contexto científico relevante:\n",
        "{context}\n",
        "\n",
        "\n",
        "Pergunta: {question}\n",
        "Resposta:\n",
        "\"\"\"\n",
        "  return llm(prompt)[0]['generated_text']"
      ],
      "metadata": {
        "id": "-rtcoC5nOohs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste Básico do Modelo\n"
      ],
      "metadata": {
        "id": "mt3Jqcl4SMF2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06713958"
      },
      "source": [
        "question = \"O que a literatura indica sobre o uso de aspirina em prevenção primária?\"\n",
        "print(medical_chat(question))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Qual medicamento é eficaz para pedra nos rins?\"\n",
        "print(medical_chat(question))"
      ],
      "metadata": {
        "id": "WqNZH4yyZeiL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aRFH2sIYarWe"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}