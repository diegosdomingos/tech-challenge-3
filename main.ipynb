{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instala bibliotecas necess√°rias e importa m√≥dulos essenciais.\n",
        "\n"
      ],
      "metadata": {
        "id": "fdfFPEJL3CLJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rszAxEbZOA43"
      },
      "outputs": [],
      "source": [
        "!pip install -q unsloth[colab-new] faiss-cpu sentence-transformers datasets accelerate trl peft transformers\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "from transformers import pipeline\n",
        "from transformers import TrainingArguments\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from trl import SFTTrainer\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "from datetime import date, timedelta"
      ],
      "metadata": {
        "id": "X1lx49AcLtBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7E3NuKW6Lyjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WyGzkc5ez3a"
      },
      "source": [
        "# Download e explora√ß√£o inicial dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CuxJtGggAxGf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/pubmedqa/pubmedqa.git\n",
        "\n",
        "file_path = 'pubmedqa/data/ori_pqal.json'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "sample_key = list(data.keys())[0]\n",
        "print(f\"\\nCampos dispon√≠veis: {list(data[sample_key].keys())}\\n\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Explora√ß√£o de dados - PubMedQA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, key in enumerate(list(data.keys())[:3]):\n",
        "    item = data[key]\n",
        "\n",
        "    print(f\"\\nExemplo {i+1} | ID: {key}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"Question: {item.get('QUESTION', 'N/A')}\")\n",
        "\n",
        "    context = \" \".join(item.get('CONTEXTS', []))\n",
        "    print(f\"Context: {context[:300]}...\")\n",
        "\n",
        "    print(f\"Labels: {item.get('LABELS', 'N/A')}\")\n",
        "    print(f\"Decision: {item.get('final_decision', 'N/A')}\")\n",
        "    print(f\"Answer: {item.get('LONG_ANSWER', 'N/A')[:200]}...\")\n",
        "    print(f\"Meshes: {item.get('MESHES', 'N/A')}\")\n",
        "    print(f\"Year: {item.get('YEAR', 'N/A')}\")\n",
        "    print(f\"Reasoning required pred: {item.get('reasoning_required_pred', 'N/A')}\")\n",
        "    print(f\"Reasoning free pred: {item.get('reasoning_free_pred', 'N/A')}\")\n",
        "\n",
        "print(f\"\\n\\nTotal de registros: {len(data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFH2sIYarWe"
      },
      "source": [
        "# Pr√©-processamento - Limpeza, Normaliza√ß√£o e Anonimiza√ß√£o dos Textos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4fd06e94"
      },
      "outputs": [],
      "source": [
        "MAP_DECISION = {\n",
        "  \"yes\": \"SIM\",\n",
        "  \"no\": \"N√ÉO\",\n",
        "  \"maybe\": \"TALVEZ\"\n",
        "}\n",
        "\n",
        "\n",
        "def anonymize_text(text):\n",
        "    \"\"\"Remove dados sens√≠veis (LGPD/HIPAA compliance)\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'(Dr\\.|Dra\\.|Doctor|Prof\\.|MD)\\s+[A-Z][a-z]+(\\s+[A-Z][a-z]+)?', '[NOME]', text)\n",
        "    text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', '[EMAIL]', text)\n",
        "    locations = r'(Israel|Denmark|Chile|Texas|France|United Kingdom|UK|USA|Pakistan|Karachi|Jordan|Japan|Australia|North Carolina|Washington)'\n",
        "    text = re.sub(locations, '[LOCAL]', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\b\\d{6,}\\b', '[ID]', text)\n",
        "    text = re.sub(r'\\b(19|20)\\d{2}\\b', '[ANO]', text)\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '[URL]', text)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "  if not text:\n",
        "    return \"\"\n",
        "  text = unicodedata.normalize(\"NFKC\", text)\n",
        "  text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "  text = anonymize_text(text)\n",
        "\n",
        "  return text\n",
        "\n",
        "\n",
        "processed_docs = []\n",
        "\n",
        "for item in data.values():\n",
        "  question = clean_text(item.get(\"QUESTION\"))\n",
        "  context = clean_text(\" \".join(item.get(\"CONTEXTS\", [])))\n",
        "  answer = clean_text(item.get(\"LONG_ANSWER\", \"\"))\n",
        "  decision = MAP_DECISION.get(item.get(\"final_decision\", \"\"), \"\")\n",
        "\n",
        "\n",
        "  if question and context:\n",
        "    processed_docs.append({\n",
        "      \"question\": question,\n",
        "      \"context\": context,\n",
        "      \"answer\": answer,\n",
        "      \"decision\": decision,\n",
        "      \"year\": item.get(\"YEAR\")\n",
        "    })\n",
        "\n",
        "\n",
        "print(len(processed_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparando conjunto de dados em portugu√™s para treino de tradu√ß√£o"
      ],
      "metadata": {
        "id": "eOou-BxIaFMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/diegosdomingos/tech-challenge-3.git\n",
        "\n",
        "file_path = 'tech-challenge-3/data/language_alignment_pt.jsonl'\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/rag/language_alignment_pt.jsonl\",  #Alterar quando o dataset j√° estiver na main\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "print(dataset.column_names)\n",
        "\n",
        "def messages_to_text(example):\n",
        "    text = \"\"\n",
        "    for msg in example[\"messages\"]:\n",
        "        if msg[\"role\"] == \"system\":\n",
        "            text += f\"<<SYS>>\\n{msg['content']}\\n<</SYS>>\\n\\n\"\n",
        "        elif msg[\"role\"] == \"user\":\n",
        "            text += f\"[INST] {msg['content']} [/INST]\\n\"\n",
        "        elif msg[\"role\"] == \"assistant\":\n",
        "            text += msg[\"content\"]\n",
        "    return {\"text\": text}\n",
        "\n",
        "dataset = dataset.map(\n",
        "    messages_to_text,\n",
        "    batched=False,\n",
        "    remove_columns=[\"messages\"]\n",
        ")\n",
        "\n",
        "print(dataset.column_names)\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "id": "Q3r9Q4rFGh0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estrutura√ß√£o de Documentos para RAG (Recupera√ß√£o + Gera√ß√£o)\n",
        "## - Cria textos formatados unificando quest√£o, contexto e resposta para busca sem√¢ntica."
      ],
      "metadata": {
        "id": "CN9H1ot25hIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_documents = []\n",
        "\n",
        "for d in processed_docs:\n",
        "  text = f\"\"\"\n",
        "  Pergunta cient√≠fica:\n",
        "  {d['question']}\n",
        "\n",
        "\n",
        "  Evid√™ncia:\n",
        "  {d['context']}\n",
        "\n",
        "\n",
        "  Conclus√£o:\n",
        "  {d['answer']}\n",
        "  \"\"\"\n",
        "  rag_documents.append(text.strip())\n",
        "\n",
        "\n",
        "len(rag_documents)"
      ],
      "metadata": {
        "id": "jdL40-3R5nXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gera√ß√£o de Embeddings e Constru√ß√£o de √çndice FAISS"
      ],
      "metadata": {
        "id": "236_nIoK52PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "embeddings = embedder.encode(rag_documents, show_progress_bar=True)\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(np.array(embeddings))\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('/content/drive/MyDrive/rag', exist_ok=True)\n",
        "\n",
        "faiss.write_index(index, \"/content/drive/MyDrive/rag/medical_index.faiss\")\n",
        "\n",
        "with open('/content/drive/MyDrive/rag/medical_docs.json', 'w') as f:\n",
        "  json.dump(rag_documents, f)"
      ],
      "metadata": {
        "id": "hm0TXEBX56wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cria√ß√£o de dataset de prontu√°rio (Fict√≠cio) com SQLite"
      ],
      "metadata": {
        "id": "Y-fFDBx0LMFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DB_PATH = \"prontuarios.db\"\n",
        "\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS pacientes (\n",
        "    patient_id TEXT PRIMARY KEY,\n",
        "    nome TEXT,\n",
        "    data_nascimento TEXT,\n",
        "    idade INTEGER,\n",
        "    sexo TEXT,\n",
        "    alergias TEXT,\n",
        "    comorbidades TEXT\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS atendimentos (\n",
        "    atendimento_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    patient_id TEXT,\n",
        "    data_atendimento TEXT,\n",
        "    queixa_principal TEXT,\n",
        "    anamnese TEXT,\n",
        "    diagnostico TEXT,\n",
        "    conduta TEXT,\n",
        "    tratamentos_em_andamento TEXT,\n",
        "    exames_solicitados TEXT,\n",
        "    observacoes TEXT,\n",
        "    FOREIGN KEY(patient_id) REFERENCES pacientes(patient_id)\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "GZVUcyAWLQhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Populando os dados fict√≠cios"
      ],
      "metadata": {
        "id": "p5XrRqtaO2C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nomes = [\n",
        "    \"Ana Paula Souza\", \"Ana Carolina Lima\", \"Bruno Silva\", \"Carlos Eduardo Rocha\",\n",
        "    \"Daniela Martins\", \"Eduardo Nogueira\", \"Fernanda Alves\", \"Gabriel Pacheco\",\n",
        "    \"Helena Ribeiro\", \"Igor Farias\", \"Juliana Torres\", \"Lucas Fernandes\",\n",
        "    \"Mariana Araujo\", \"Natalia Pacheco\", \"Otavio Nunes\", \"Paula Guedes\",\n",
        "    \"Rafael Moreira\", \"Sabrina Lopes\", \"Thiago Barros\", \"Vanessa Farias\",\n",
        "    \"William Teixeira\", \"Ana Beatriz Costa\"\n",
        "]\n",
        "\n",
        "diagnosticos = [\n",
        "    \"Hipertens√£o arterial sist√™mica\",\n",
        "    \"Diabetes mellitus tipo 2\",\n",
        "    \"Asma br√¥nquica\",\n",
        "    \"Infec√ß√£o do trato urin√°rio\",\n",
        "    \"Pneumonia adquirida na comunidade\",\n",
        "    \"Transtorno de ansiedade generalizada\",\n",
        "    \"Gastrite cr√¥nica\",\n",
        "    \"Enxaqueca cr√¥nica\"\n",
        "]\n",
        "\n",
        "alergias_lista = [\n",
        "    \"Dipirona\", \"Penicilina\", \"Sulfa\", \"Nenhuma conhecida\"\n",
        "]\n",
        "\n",
        "comorbidades_lista = [\n",
        "    \"Hipertens√£o\", \"Diabetes\", \"Dislipidemia\", \"Obesidade\", \"Nenhuma\"\n",
        "]\n",
        "\n",
        "def gerar_data_nascimento(idade):\n",
        "    hoje = date.today()\n",
        "    return hoje - timedelta(days=idade * 365)\n",
        "\n",
        "conn = sqlite3.connect(DB_PATH)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "for i, nome in enumerate(nomes, start=1):\n",
        "    idade = random.randint(18, 85)\n",
        "    patient_id = f\"PAT{i:04d}\"\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        INSERT OR IGNORE INTO pacientes\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "    \"\"\", (\n",
        "        patient_id,\n",
        "        nome,\n",
        "        gerar_data_nascimento(idade).isoformat(),\n",
        "        idade,\n",
        "        random.choice([\"F\", \"M\"]),\n",
        "        random.choice(alergias_lista),\n",
        "        random.choice(comorbidades_lista)\n",
        "    ))\n",
        "\n",
        "    for _ in range(random.randint(1, 4)):\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO atendimentos (\n",
        "                patient_id,\n",
        "                data_atendimento,\n",
        "                queixa_principal,\n",
        "                anamnese,\n",
        "                diagnostico,\n",
        "                conduta,\n",
        "                tratamentos_em_andamento,\n",
        "                exames_solicitados,\n",
        "                observacoes\n",
        "            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\", (\n",
        "            patient_id,\n",
        "            (date.today() - timedelta(days=random.randint(1, 1200))).isoformat(),\n",
        "            \"Dor, mal-estar e sintomas gerais\",\n",
        "            \"Paciente relata in√≠cio dos sintomas h√° alguns dias, sem fatores agravantes claros.\",\n",
        "            random.choice(diagnosticos),\n",
        "            \"Conduta expectante e acompanhamento ambulatorial\",\n",
        "            \"Uso cont√≠nuo de medica√ß√£o conforme prescri√ß√£o\",\n",
        "            \"Hemograma completo, glicemia, PCR\",\n",
        "            \"Paciente orientado quanto aos sinais de alarme\"\n",
        "        ))\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "qiKMx2FwO039"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configura√ß√£o do Modelo para Treinamento com LoRA\n",
        "## - Carrega modelo base e aplica adapta√ß√£o LoRA para reduzir custo de treino."
      ],
      "metadata": {
        "id": "l9uXJezHAtls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0.05,\n",
        ")"
      ],
      "metadata": {
        "id": "vaTkGNFE8NhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento Supervisionado do Assistente M√©dico em Portugu√™s"
      ],
      "metadata": {
        "id": "-rgHPIbcaTwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset, #DataSet com dados Em Portugu√™s\n",
        "    args=training_args,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=512,\n",
        "    packing=False\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "sefogQu3LnHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autentica√ß√£o e Upload do Modelo Treinado no HuggingFace"
      ],
      "metadata": {
        "id": "mWe9atPtaZ8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Opicional: Subir modelo no Hugging Face\n",
        "ENV_PATH = \"/content/drive/MyDrive/token-hf/env\"\n",
        "load_dotenv(ENV_PATH)\n",
        "\n",
        "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "login(token=HF_TOKEN)\n",
        "\n",
        "HF_REPO = f\"{os.getenv(\"HF_USER_REPO\")}/assistente-medico-lora\"\n",
        "\n",
        "model.push_to_hub(HF_REPO)\n",
        "tokenizer.push_to_hub(HF_REPO)"
      ],
      "metadata": {
        "id": "8WSXHwDBXptL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configura√ß√£o da Pipeline de Gera√ß√£o + Prompt do Assistente M√©dico"
      ],
      "metadata": {
        "id": "vDpkA6Dla3rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "Voc√™ √© um assistente m√©dico virtual.\n",
        "Responda sempre em portugu√™s, com linguagem clara, emp√°tica e baseada em evid√™ncias cient√≠ficas.\n",
        "\n",
        "Regras:\n",
        "- N√£o invente informa√ß√µes.\n",
        "- Se n√£o houver evid√™ncia suficiente, diga isso explicitamente.\n",
        "- N√£o prescreva rem√©dios ou medicamentos, e nem indique tratamentos espec√≠ficos.\n",
        "- Quando perguntarem por algum rem√©dio, voc√™ deve responder: N√£o estou autorizado a prescrever medicamentos, por favor, consulte um m√©dico. <FIM>\n",
        "- Sempre cite a fonte da informa√ß√£o cient√≠fica\n",
        "\n",
        "Importante:\n",
        "- Responda de forma resumida e objetiva e finalize sempre a primeira resposta objetiva com o texto: <FIM>\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/drive/MyDrive/rag/medical_docs.json') as f:\n",
        "  docs = json.load(f)\n",
        "\n",
        "index = faiss.read_index('/content/drive/MyDrive/rag/medical_index.faiss')\n",
        "\n",
        "\n",
        "llm_consulta = pipeline(\n",
        "  \"text-generation\",\n",
        "  model=model,\n",
        "  tokenizer=tokenizer,\n",
        "  max_new_tokens=250,\n",
        "  temperature=0.0,\n",
        "  do_sample=False,\n",
        "  repetition_penalty=1.1,\n",
        "  return_full_text=False,\n",
        "  eos_token_id=tokenizer.eos_token_id\n",
        "  )\n",
        "\n",
        "def retrieve_context(question, k=3):\n",
        "  q_emb = embedder.encode([question])\n",
        "  _, idx = index.search(q_emb, k)\n",
        "  return \"\\n\\n\".join([docs[i] for i in idx[0]])\n",
        "\n",
        "def medical_chat(question):\n",
        "\n",
        "  # Adiciona <FIM> ao final da string `question` se n√£o estiver presente\n",
        "  if \"<FIM>\" not in question:\n",
        "    question += \" <FIM>\"\n",
        "\n",
        "  context = retrieve_context(question)\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "{SYSTEM_PROMPT}\n",
        "\n",
        "\n",
        "Contexto cient√≠fico relevante:\n",
        "{context}\n",
        "\n",
        "\n",
        "Pergunta: {question}\n",
        "Resposta:\n",
        "\"\"\"\n",
        "  output = llm_consulta(prompt)[0][\"generated_text\"]\n",
        "\n",
        "  # üîí corta tudo depois do token de fim\n",
        "  output = output.split(\"<FIM>\")[0]\n",
        "\n",
        "  return output.strip()"
      ],
      "metadata": {
        "id": "-rtcoC5nOohs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regras para consultar prontu√°rios"
      ],
      "metadata": {
        "id": "FALsGqFcO8Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_pacientes_por_nome(nome_parcial: str):\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "    bind = nome_parcial.strip()\n",
        "\n",
        "    #print('[DEBUG BIND]', bind)\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT patient_id, nome, idade\n",
        "        FROM pacientes\n",
        "        WHERE LOWER(nome) LIKE LOWER(?)\n",
        "        OR LOWER(nome) LIKE LOWER(? || ' %')\n",
        "        OR LOWER(nome) LIKE LOWER('% ' || ? || ' %')\n",
        "        OR LOWER(nome) LIKE LOWER('% ' || ?)\n",
        "    \"\"\", (bind, bind, bind, bind))\n",
        "\n",
        "    resultados = cursor.fetchall()\n",
        "    conn.close()\n",
        "    #print('[DEBUG RESULT]', resultados)\n",
        "    return resultados\n",
        "\n",
        "\n",
        "def buscar_prontuario_por_patient_id(patient_id: int):\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "        SELECT diagnostico, observacoes\n",
        "        FROM atendimentos\n",
        "        WHERE patient_id = ?\n",
        "    \"\"\", (patient_id,))\n",
        "\n",
        "    prontuario = cursor.fetchone()\n",
        "    conn.close()\n",
        "    return prontuario\n"
      ],
      "metadata": {
        "id": "ToC5i_h-TwaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testes de Consulta ao Assistente M√©dico com Exemplos\n"
      ],
      "metadata": {
        "id": "mt3Jqcl4SMF2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06713958"
      },
      "source": [
        "# Teste normal de consulta\n",
        "question = \"O que a literatura indica sobre o uso de aspirina em preven√ß√£o prim√°ria?\"\n",
        "print(f\"Resposta 1 (normal): {medical_chat(question)}\")\n",
        "\n",
        "# Testa restri√ß√£o\n",
        "question = \"Qual medicamento √© eficaz para pedra nos rins?\"\n",
        "print(f\"Resposta 2 (restri√ß√£o): {medical_chat(question)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faz o Router e prepara o CHAT Assistente\n"
      ],
      "metadata": {
        "id": "b449ih0OGNia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSIFICADOR_PROMPT = \"\"\"\n",
        "Analise a mensagem do usu√°rio e retorne APENAS um JSON v√°lido.\n",
        "\n",
        "Classifica√ß√µes poss√≠veis:\n",
        "- INVALIDA\n",
        "- INDEVIDA\n",
        "- PRECISA_MAIS_INFO\n",
        "- PRONTUARIO\n",
        "- QA\n",
        "\n",
        "Regras:\n",
        "1. PRONTUARIO ‚Üí consulta sobre dados cl√≠nicos de um paciente espec√≠fico. Obrigat√≥riamente deve receber o nome do paciente.\n",
        "\n",
        "2. PRECISA_MAIS_INFO ‚Üí consulta sobre dados cl√≠nicos de um paciente espec√≠fico, por√©m sem informar dados que possam identificar esse paciente (Nome, por exemplo)\n",
        "Exemplo: consultar prontu√°rio, trazer hist√≥rico de pacientes, consultar caso de febre, ou seja, qualquer solicita√ß√£o sem especificar o paciente alvo.\n",
        "\n",
        "3. QA ‚Üí pergunta cient√≠fica ou t√©cnica geral\n",
        "Exemplo: Qual √© o meio de transmiss√£o da febre amarela?, COVID √© transmiss√≠vel mesmo com m√°scara?, A vacina da gripe √© 100% eficaz para preven√ß√£o de infec√£o?\n",
        "\n",
        "4. INVALIDA ‚Üí textos vagos, sem sentido ou que n√£o seja poss√≠vel interpretar sem mais informa√ß√µes.\n",
        "Exemplo: palavras soltas, palavras desconhecidas, frases sem sentido, idiomas desconhecidos.\n",
        "\n",
        "5. INDEVIDA -> Solicita√ß√µes de recomenda√ß√£o direta de rem√©dio, medicamentos ou tratamentos.\n",
        "Exemplo: Qual o melhor rem√©dio para inflama√ß√£o?, Quantos gramas devo tomar de dipirona?, Indique um bom rem√©dio para dor de dentes?, O que devo tomar para enxaqueca?\n",
        "\n",
        "Formato EXATO da resposta (obrigat√≥rio):\n",
        "{{\"classificacao\": \"<UMA_DAS_OPCOES>\"}} \"<FIM>\"\n",
        "\n",
        "Mensagem do usu√°rio:\n",
        "\\\"\\\"\\\"{mensagem}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "EXTRATOR_NOME_PROMPT = \"\"\"\n",
        "Extraia o NOME do paciente mencionado na mensagem.\n",
        "\n",
        "Regras obrigat√≥rias:\n",
        "- Se houver nome E sobrenome, retorne o nome completo\n",
        "- Se houver APENAS um nome (ex: \"Ana\"), retorne esse nome\n",
        "- Se houver um √∫nico nome pr√≥prio comum em portugu√™s, retorne esse nome\n",
        "- N√£o invente sobrenomes\n",
        "- N√£o inclua aspas, colchetes ou marcadores de chat\n",
        "- Se n√£o houver nenhum nome identific√°vel, retorne: NAO_IDENTIFICADO\n",
        "\n",
        "Formato EXATO da resposta (Obrigat√≥rio):\n",
        "<nome_do_paciente>\n",
        "<FIM>\n",
        "\n",
        "Mensagem:\n",
        "\\\"\\\"\\\"{mensagem}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "llm_chat = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "llm_extracao = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=80,\n",
        "    do_sample=False,\n",
        "    temperature=0.0,\n",
        "    return_full_text=False\n",
        ")\n",
        "\n",
        "estado_chat = {\n",
        "    \"modo\": None,            # None | \"PRONTUARIO\"\n",
        "    \"dados_parciais\": {}     # ex: {\"nome_paciente\": \"...\"}\n",
        "}\n",
        "\n",
        "def limpar_estado():\n",
        "    estado_chat[\"modo\"] = None\n",
        "    estado_chat[\"dados_parciais\"].clear()\n",
        "\n",
        "def formatar_chat_llama(system_prompt: str, user_prompt: str) -> str:\n",
        "    return f\"\"\"<|begin_of_text|>\n",
        "<|system|>\n",
        "{system_prompt}\n",
        "<|user|>\n",
        "{user_prompt}\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "def extrair_nome_paciente(mensagem: str) -> str | None:\n",
        "    system_prompt = (\n",
        "        \"Voc√™ extrai nomes de texto com alta precis√£o.\"\n",
        "        )\n",
        "\n",
        "    user_prompt = EXTRATOR_NOME_PROMPT.format(mensagem=mensagem)\n",
        "\n",
        "    prompt = formatar_chat_llama(system_prompt, user_prompt)\n",
        "\n",
        "    #print(\"PROMPT\", prompt)\n",
        "\n",
        "    output = llm_extracao(\n",
        "        prompt,\n",
        "        max_new_tokens=80,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "        return_full_text=False\n",
        "    )\n",
        "\n",
        "    #print(\"RAW OUTPUT:\", output)\n",
        "\n",
        "    if not output or not output[0][\"generated_text\"]:\n",
        "        return None\n",
        "\n",
        "    #print(['DEBUG OUTPUT'], output)\n",
        "\n",
        "    nome = output[0][\"generated_text\"].strip()\n",
        "\n",
        "    #print(['DEBUG NOME'], nome)\n",
        "\n",
        "    if \"<FIM>\" not in nome:\n",
        "      return None\n",
        "\n",
        "    if \"<FIM>\" in nome:\n",
        "      nome = nome.split(\"<FIM>\")[0].strip()\n",
        "\n",
        "    #print(['DEBUG NOME'], nome)\n",
        "\n",
        "    if nome == \"NAO_IDENTIFICADO\" or not nome:\n",
        "        return None\n",
        "\n",
        "    return nome\n",
        "\n",
        "def resposta_invalida():\n",
        "    return (\n",
        "        \"Tive dificuldade para entender sua mensagem \\n\\n\"\n",
        "        \"Voc√™ pode reformular ou explicar um pouco melhor o que precisa?\"\n",
        "    )\n",
        "\n",
        "def resposta_pedir_mais_info():\n",
        "    return (\n",
        "        \"N√£o foi poss√≠vel identificar o paciente em quest√£o \\n\\n\"\n",
        "        \"Verifique se digitou o nome do paciente corretamente\"\n",
        "    )\n",
        "\n",
        "def resposta_indevida():\n",
        "    return (\n",
        "        \"N√£o tenho permiss√£o para responder este tipo de d√∫vida  \\n\\n\"\n",
        "        \"Somente um M√©dico est√° apto para receitar ou indicar medicamentos\"\n",
        "    )\n",
        "\n",
        "def responder_prontuario_com_nome(nome: str):\n",
        "    pacientes = buscar_pacientes_por_nome(nome)\n",
        "\n",
        "    if not pacientes:\n",
        "        limpar_estado()\n",
        "        return f\"N√£o encontrei nenhum prontu√°rio para {nome}.\"\n",
        "\n",
        "    if len(pacientes) > 1:\n",
        "        lista = \"\\n\".join(\n",
        "            f\"- {p[1]} (idade: {p[2]})\"\n",
        "            for p in pacientes\n",
        "        )\n",
        "        return (\n",
        "            \"Encontrei mais de um paciente com esse nome \\n\\n\"\n",
        "            \"Por favor, confirme qual deles voc√™ deseja consultar:\\n\"\n",
        "            f\"{lista}\"\n",
        "        )\n",
        "\n",
        "    patient_id, nome_completo, idade = pacientes[0]\n",
        "    prontuario = buscar_prontuario_por_patient_id(patient_id)\n",
        "\n",
        "    limpar_estado()\n",
        "\n",
        "    diagnostico, observacoes = prontuario\n",
        "\n",
        "    return (\n",
        "        \"Prontu√°rio do paciente\\n\\n\"\n",
        "        f\"‚Ä¢ Nome: {nome_completo}\\n\"\n",
        "        f\"‚Ä¢ Idade: {idade}\\n\"\n",
        "        f\"‚Ä¢ Diagn√≥stico: {diagnostico}\\n\"\n",
        "        f\"‚Ä¢ Observa√ß√µes: {observacoes}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def responder_qa(mensagem):\n",
        "    resposta = medical_chat(mensagem)\n",
        "\n",
        "    if not resposta:\n",
        "        return (\n",
        "            \"N√£o encontrei uma resposta cient√≠fica clara no material dispon√≠vel üìö\\n\\n\"\n",
        "            \"Se quiser, pode reformular a pergunta.\"\n",
        "        )\n",
        "\n",
        "    return resposta\n",
        "\n",
        "def extrair_classificacao(resposta: str) -> str:\n",
        "    if \"<FIM>\" in resposta:\n",
        "      resposta = resposta.split(\"<FIM>\")[0].strip()\n",
        "\n",
        "    json_str = resposta.strip()\n",
        "\n",
        "    try:\n",
        "        return json.loads(json_str)[\"classificacao\"].upper()\n",
        "    except Exception:\n",
        "        return \"INVALIDA\"\n",
        "\n",
        "def classificar_mensagem(mensagem: str) -> str:\n",
        "    system_prompt = (\n",
        "        \"Voc√™ √© um assistente respons√°vel apenas por classificar mensagens. \"\n",
        "        \"Siga estritamente o formato solicitado.\"\n",
        "    )\n",
        "\n",
        "    user_prompt = CLASSIFICADOR_PROMPT.format(mensagem=mensagem)\n",
        "\n",
        "    prompt = formatar_chat_llama(system_prompt, user_prompt)\n",
        "\n",
        "    output = llm_chat(\n",
        "        prompt,\n",
        "        max_new_tokens=50,\n",
        "        do_sample=False,\n",
        "        temperature=0.0,\n",
        "        return_full_text=False\n",
        "    )\n",
        "\n",
        "    resposta = output[0][\"generated_text\"].strip()\n",
        "\n",
        "    return extrair_classificacao(resposta)\n",
        "\n",
        "def chat_router(mensagem: str):\n",
        "    global estado_chat\n",
        "\n",
        "    if estado_chat[\"modo\"] == \"PRONTUARIO\":\n",
        "        nome = extrair_nome_paciente(mensagem)\n",
        "\n",
        "        if not nome:\n",
        "            return (\n",
        "                \"Ainda preciso do nome completo do paciente para continuar\"\n",
        "            )\n",
        "\n",
        "        limpar_estado()\n",
        "        return responder_prontuario_com_nome(nome)\n",
        "\n",
        "    classificacao = classificar_mensagem(mensagem)\n",
        "\n",
        "    print(\"Assunto: \",classificacao)\n",
        "\n",
        "    if classificacao == \"PRONTUARIO\":\n",
        "\n",
        "        nome = extrair_nome_paciente(mensagem)\n",
        "\n",
        "        if nome:\n",
        "            return responder_prontuario_com_nome(nome)\n",
        "\n",
        "        limpar_estado()\n",
        "        estado_chat[\"modo\"] = \"PRONTUARIO\"\n",
        "        return (\n",
        "            \"Certo, vou consultar um prontu√°rio \\n\\n\"\n",
        "            \"Pode me informar o nome completo do paciente?\"\n",
        "        )\n",
        "\n",
        "    if classificacao == \"QA\":\n",
        "        limpar_estado()\n",
        "        return responder_qa(mensagem)\n",
        "\n",
        "    if classificacao == \"PRECISA_MAIS_INFO\":\n",
        "        limpar_estado()\n",
        "        return resposta_pedir_mais_info()\n",
        "\n",
        "    if classificacao == \"INDEVIDA\":\n",
        "        limpar_estado()\n",
        "        return resposta_indevida()\n",
        "\n",
        "    return resposta_invalida()\n",
        "\n"
      ],
      "metadata": {
        "id": "fEuzTZ3N2fqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "print(\"Assistente M√©dico iniciado\")\n",
        "print(\"Digite 'sair' para encerrar\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Voc√™: \").strip()\n",
        "\n",
        "    if user_input.lower() in [\"sair\", \"exit\", \"quit\"]:\n",
        "        print(\"Assistente: Sess√£o encerrada.\")\n",
        "        break\n",
        "\n",
        "    resposta = chat_router(user_input)\n",
        "    print(f\"\\nAssistente: {resposta}\\n\")\n",
        "    print(\"\\n\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "o3v0HtQ3GSCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aRFH2sIYarWe"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}