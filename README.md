# ğŸ§  Assistente MÃ©dico Inteligente com RAG e LLM em PortuguÃªs

## ğŸ¯ Objetivo do Projeto

Este projeto tem como objetivo desenvolver um **assistente mÃ©dico inteligente em portuguÃªs**, combinando **Large Language Models (LLMs)** com **Retrieval-Augmented Generation (RAG)** e um **banco de dados clÃ­nico simulado**.

O assistente Ã© capaz de:
- Identificar e buscar pacientes em um banco de dados
- Consultar histÃ³rico de atendimentos mÃ©dicos fictÃ­cios
- Realizar buscas semÃ¢nticas em bases mÃ©dicas cientÃ­ficas
- Responder perguntas mÃ©dicas de forma clara, contextualizada e segura
- Controlar o fluxo conversacional por estados (ex.: aguardando nome do paciente)

âš ï¸ **Todos os dados clÃ­nicos sÃ£o fictÃ­cios** e utilizados apenas para fins educacionais.

---

## ğŸš€ Passo a Passo para Clonar, Abrir e Executar

### 1ï¸âƒ£ Clonar o RepositÃ³rio (branch correta)
```bash
git clone -b branch_diego_assistant https://github.com/diegosdomingos/tech-challenge-3.git
```
### 2ï¸âƒ£ Abrir o Notebook
Abra o arquivo `main.ipynb` no Google Colab (recomendado)

### 3ï¸âƒ£ Instalar DependÃªncias
Execute as cÃ©lulas iniciais do notebook, que instalam automaticamente as dependÃªncias:

```bash
pip install -q unsloth[colab-new] faiss-cpu sentence-transformers trl datasets scikit-learn
pip install --no-deps xformers "trl<0.9.0" peft accelerate bitsandbytes
pip install -U spacy transformers accelerate
python -m spacy download pt_core_news_lg
```

---

### 4ï¸âƒ£ Configurar VariÃ¡veis de Ambiente
Crie um arquivo `.env` com (Passo opicional para salvar modelo no HuggingFace):

```
HF_TOKEN=seu_token_huggingface
HF_USER_REPO=seu_usuario/seu_repositorio
```

---

### 5ï¸âƒ£ Executar o Notebook
Execute as cÃ©lulas **em ordem**, respeitando o fluxo definido no `main.ipynb`.

---

## ğŸ“˜ ExplicaÃ§Ã£o do Notebook `main.ipynb`

### ğŸ”¹ 1. Setup Inicial
Instala e importa bibliotecas para:
- NLP em portuguÃªs
- Embeddings semÃ¢nticos
- FAISS
- Fine-tuning com LoRA
- Banco de dados SQLite
- Controle de fluxo conversacional

---

### ğŸ”¹ 2. CriaÃ§Ã£o do Banco de Dados ClÃ­nico
CriaÃ§Ã£o do banco `prontuarios.db` contendo:
- Tabela de pacientes
- Tabela de atendimentos mÃ©dicos

Os dados sÃ£o **totalmente fictÃ­cios** e simulam um cenÃ¡rio real de clÃ­nica mÃ©dica.

---

### ğŸ”¹ 3. Carregamento do Dataset MÃ©dico
Utiliza o **PubMedQA** como base de conhecimento mÃ©dico para:
- Criar documentos de contexto
- Alimentar o pipeline RAG

---

### ğŸ”¹ 4. PrÃ©-processamento e Limpeza de Texto
AplicaÃ§Ã£o de:
- NormalizaÃ§Ã£o textual
- Limpeza de dados
- PreparaÃ§Ã£o dos documentos para embeddings

---

### ğŸ”¹ 5. Embeddings e Ãndice FAISS
- GeraÃ§Ã£o de embeddings com `SentenceTransformers`
- CriaÃ§Ã£o e persistÃªncia do Ã­ndice FAISS
- Busca semÃ¢ntica eficiente para recuperaÃ§Ã£o de contexto

---

### ğŸ”¹ 6. Pipeline RAG
Integra:
- Consulta semÃ¢ntica no FAISS
- InjeÃ§Ã£o de contexto mÃ©dico no prompt
- Respostas baseadas em documentos relevantes

---

### ğŸ”¹ 7. Dataset de Alinhamento em PortuguÃªs
Carregamento do dataset `language_alignment_pt.jsonl`, utilizado para alinhar o comportamento do modelo Ã  lÃ­ngua portuguesa e ao domÃ­nio mÃ©dico.

---

### ğŸ”¹ 8. Fine-Tuning do Modelo com LoRA
- Modelo base: `unsloth/llama-3-8b-bnb-4bit`
- Treinamento supervisionado (SFT)
- Uso de LoRA para reduzir consumo de memÃ³ria e custo computacional

---

### ğŸ”¹ 9. Upload do Modelo para o Hugging Face
ApÃ³s o treinamento:
- Modelo e tokenizer sÃ£o enviados para o Hugging Face Hub
- Permite reutilizaÃ§Ã£o e inferÃªncia futura

---

### ğŸ”¹ 10. Assistente Conversacional com Controle de Estado
ImplementaÃ§Ã£o de lÃ³gica de estados, como:
- `awaiting_patient_name`
- IdentificaÃ§Ã£o do paciente
- DecisÃ£o entre busca no banco ou no RAG
- Fluxo conversacional mais realista

---

## ğŸ“Š Datasets Utilizados

| Dataset | DescriÃ§Ã£o | Fonte |
|------|---------|------|
| **PubMedQA** | Perguntas e respostas baseadas em artigos mÃ©dicos cientÃ­ficos | https://github.com/pubmedqa/pubmedqa |
| **language_alignment_pt.jsonl** | Dataset de alinhamento em portuguÃªs para uso em Fine-tuning| Incluso no repositÃ³rio |
| **dataset_intention.jsonl** | Dataset de intenÃ§Ã£o para uso em Fine-tuning| Incluso no repositÃ³rio |


---

## ğŸ§  Tecnologias Utilizadas

- Python
- Hugging Face Transformers
- Unsloth + LoRA
- FAISS
- Sentence Transformers
- SQLite
- spaCy (PortuguÃªs)
- Google Colab

---

## ğŸ“Œ ConsideraÃ§Ãµes Finais

Este projeto demonstra uma arquitetura moderna de **assistente mÃ©dico inteligente**, integrando:

- Retrieval-Augmented Generation (RAG)
- Fine-tuning eficiente de LLMs
- Banco de dados relacional
- Controle de fluxo conversacional

A soluÃ§Ã£o Ã© modular, extensÃ­vel e adequada para estudos de IA aplicada Ã  saÃºde, respeitando boas prÃ¡ticas de seguranÃ§a e Ã©tica.
